{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "## Fitting the Model"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.linear_algebra import dot, Vector\n\ndef predict(x: Vector, beta: Vector) -> float:\n    \"\"\"assumes that the first element of x is 1\"\"\"\n    return dot(x, beta)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from typing import List\n\ndef error(x: Vector, y: float, beta: Vector) -> float:\n    return predict(x, beta) - y\n\ndef squared_error(x: Vector, y: float, beta: Vector) -> float:\n    return error(x, y, beta) ** 2\n\nx = [1, 2, 3]\ny = 30\nbeta = [4, 4, 4]  # so prediction = 4 + 8 + 12 = 24\n\nassert error(x, y, beta) == -6\nassert squared_error(x, y, beta) == 36",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def sqerror_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n    err = error(x, y, beta)\n    return [2 * err * x_i for x_i in x]\n\nassert sqerror_gradient(x, y, beta) == [-12, -24, -36]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import random\nimport tqdm\nfrom scratch.linear_algebra import vector_mean\nfrom scratch.gradient_descent import gradient_step\n\n\ndef least_squares_fit(xs: List[Vector],\n                      ys: List[float],\n                      learning_rate: float = 0.001,\n                      num_steps: int = 1000,\n                      batch_size: int = 1) -> Vector:\n    \"\"\"\n    Find the beta that minimizes the sum of squared errors\n    assuming the model y = dot(x, beta).\n    \"\"\"\n    # Start with a random guess\n    guess = [random.random() for _ in xs[0]]\n\n    for _ in tqdm.trange(num_steps, desc=\"least squares fit\"):\n        for start in range(0, len(xs), batch_size):\n            batch_xs = xs[start:start+batch_size]\n            batch_ys = ys[start:start+batch_size]\n\n            gradient = vector_mean([sqerror_gradient(x, y, guess)\n                                    for x, y in zip(batch_xs, batch_ys)])\n            guess = gradient_step(guess, gradient, -learning_rate)\n\n    return guess",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.statistics import daily_minutes_good\nfrom scratch.gradient_descent import gradient_step\n\nrandom.seed(0)\n# I used trial and error to choose num_iters and step_size.\n# This will run for a while.\nlearning_rate = 0.001\n\nbeta = least_squares_fit(inputs, daily_minutes_good, learning_rate, 5000, 25)\nassert 30.50 < beta[0] < 30.70  # constant\nassert  0.96 < beta[1] <  1.00  # num friends\nassert -1.89 < beta[2] < -1.85  # work hours per day\nassert  0.91 < beta[3] <  0.94  # has PhD",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Interpreting the Model"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Goodness of Fit"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.simple_linear_regression import total_sum_of_squares\n\ndef multiple_r_squared(xs: List[Vector], ys: Vector, beta: Vector) -> float:\n    sum_of_squared_errors = sum(error(x, y, beta) ** 2\n                                for x, y in zip(xs, ys))\n    return 1.0 - sum_of_squared_errors / total_sum_of_squares(ys)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "assert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta) < 0.68",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Digression: The Bootstrap"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "data = get_sample(num_points=n)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from typing import TypeVar, Callable\n\nX = TypeVar('X')        # Generic type for data\nStat = TypeVar('Stat')  # Generic type for \"statistic\"\n\ndef bootstrap_sample(data: List[X]) -> List[X]:\n    \"\"\"randomly samples len(data) elements with replacement\"\"\"\n    return [random.choice(data) for _ in data]\n\ndef bootstrap_statistic(data: List[X],\n                        stats_fn: Callable[[List[X]], Stat],\n                        num_samples: int) -> List[Stat]:\n    \"\"\"evaluates stats_fn on num_samples bootstrap samples from data\"\"\"\n    return [stats_fn(bootstrap_sample(data)) for _ in range(num_samples)]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# 101 points all very close to 100\nclose_to_100 = [99.5 + random.random() for _ in range(101)]\n\n# 101 points, 50 of them near 0, 50 of them near 200\nfar_from_100 = ([99.5 + random.random()] +\n                [random.random() for _ in range(50)] +\n                [200 + random.random() for _ in range(50)])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.statistics import median, standard_deviation\n\nmedians_close = bootstrap_statistic(close_to_100, median, 100)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "medians_far = bootstrap_statistic(far_from_100, median, 100)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "assert standard_deviation(medians_close) < 1\nassert standard_deviation(medians_far) > 90",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Standard Errors of Regression Coefficients"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from typing import Tuple\n\nimport datetime\n\ndef estimate_sample_beta(pairs: List[Tuple[Vector, float]]):\n    x_sample = [x for x, _ in pairs]\n    y_sample = [y for _, y in pairs]\n    beta = least_squares_fit(x_sample, y_sample, learning_rate, 5000, 25)\n    print(\"bootstrap sample\", beta)\n    return beta\n\nrandom.seed(0) # so that you get the same results as me\n\n# This will take a couple of minutes!\nbootstrap_betas = bootstrap_statistic(list(zip(inputs, daily_minutes_good)),\n                                      estimate_sample_beta,\n                                      100)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "bootstrap_standard_errors = [\n    standard_deviation([beta[i] for beta in bootstrap_betas])\n    for i in range(4)]\n\nprint(bootstrap_standard_errors)\n\n# [1.272,    # constant term, actual error = 1.19\n#  0.103,    # num_friends,   actual error = 0.080\n#  0.155,    # work_hours,    actual error = 0.127\n#  1.249]    # phd,           actual error = 0.998",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.probability import normal_cdf\n\ndef p_value(beta_hat_j: float, sigma_hat_j: float) -> float:\n    if beta_hat_j > 0:\n        # if the coefficient is positive, we need to compute twice the\n        # probability of seeing an even *larger* value\n        return 2 * (1 - normal_cdf(beta_hat_j / sigma_hat_j))\n    else:\n        # otherwise twice the probability of seeing a *smaller* value\n        return 2 * normal_cdf(beta_hat_j / sigma_hat_j)\n\nassert p_value(30.58, 1.27)   < 0.001  # constant term\nassert p_value(0.972, 0.103)  < 0.001  # num_friends\nassert p_value(-1.865, 0.155) < 0.001  # work_hours\nassert p_value(0.923, 1.249)  > 0.4    # phd",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Regularization"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# alpha is a *hyperparameter* controlling how harsh the penalty is.\n# Sometimes it's called \"lambda\" but that already means something in Python.\ndef ridge_penalty(beta: Vector, alpha: float) -> float:\n    return alpha * dot(beta[1:], beta[1:])\n\ndef squared_error_ridge(x: Vector,\n                        y: float,\n                        beta: Vector,\n                        alpha: float) -> float:\n    \"\"\"estimate error plus ridge penalty on beta\"\"\"\n    return error(x, y, beta) ** 2 + ridge_penalty(beta, alpha)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.linear_algebra import add\n\ndef ridge_penalty_gradient(beta: Vector, alpha: float) -> Vector:\n    \"\"\"gradient of just the ridge penalty\"\"\"\n    return [0.] + [2 * alpha * beta_j for beta_j in beta[1:]]\n\ndef sqerror_ridge_gradient(x: Vector,\n                           y: float,\n                           beta: Vector,\n                           alpha: float) -> Vector:\n    \"\"\"\n    the gradient corresponding to the ith squared error term\n    including the ridge penalty\n    \"\"\"\n    return add(sqerror_gradient(x, y, beta),\n               ridge_penalty_gradient(beta, alpha))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "random.seed(0)\nbeta_0 = least_squares_fit_ridge(inputs, daily_minutes_good, 0.0,  # alpha\n                                 learning_rate, 5000, 25)\n# [30.51, 0.97, -1.85, 0.91]\nassert 5 < dot(beta_0[1:], beta_0[1:]) < 6\nassert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_0) < 0.69",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "beta_0_1 = least_squares_fit_ridge(inputs, daily_minutes_good, 0.1,  # alpha\n                                   learning_rate, 5000, 25)\n# [30.8, 0.95, -1.83, 0.54]\nassert 4 < dot(beta_0_1[1:], beta_0_1[1:]) < 5\nassert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_0_1) < 0.69\n\nbeta_1 = least_squares_fit_ridge(inputs, daily_minutes_good, 1,  # alpha\n                                 learning_rate, 5000, 25)\n# [30.6, 0.90, -1.68, 0.10]\nassert 3 < dot(beta_1[1:], beta_1[1:]) < 4\nassert 0.67 < multiple_r_squared(inputs, daily_minutes_good, beta_1) < 0.69\n\nbeta_10 = least_squares_fit_ridge(inputs, daily_minutes_good,10,  # alpha\n                                  learning_rate, 5000, 25)\n# [28.3, 0.67, -0.90, -0.01]\nassert 1 < dot(beta_10[1:], beta_10[1:]) < 2\nassert 0.5 < multiple_r_squared(inputs, daily_minutes_good, beta_10) < 0.6",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def lasso_penalty(beta, alpha):\n    return alpha * sum(abs(beta_i) for beta_i in beta[1:])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}