{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from matplotlib import pyplot as plt\nfrom scratch.working_with_data import rescale\nfrom scratch.multiple_regression import least_squares_fit, predict\nfrom scratch.gradient_descent import gradient_step\n\nlearning_rate = 0.001\nrescaled_xs = rescale(xs)\nbeta = least_squares_fit(rescaled_xs, ys, learning_rate, 1000, 1)\n# [0.26, 0.43, -0.43]\npredictions = [predict(x_i, beta) for x_i in rescaled_xs]\n\nplt.scatter(predictions, ys)\nplt.xlabel(\"predicted\")\nplt.ylabel(\"actual\")\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## The Logistic Function"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def logistic(x: float) -> float:\n    return 1.0 / (1 + math.exp(-x))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def logistic_prime(x: float) -> float:\n    y = logistic(x)\n    return y * (1 - y)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import math\nfrom scratch.linear_algebra import Vector, dot\n\ndef _negative_log_likelihood(x: Vector, y: float, beta: Vector) -> float:\n    \"\"\"The negative log likelihood for one data point\"\"\"\n    if y == 1:\n        return -math.log(logistic(dot(x, beta)))\n    else:\n        return -math.log(1 - logistic(dot(x, beta)))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from typing import List\n\ndef negative_log_likelihood(xs: List[Vector],\n                            ys: List[float],\n                            beta: Vector) -> float:\n    return sum(_negative_log_likelihood(x, y, beta)\n               for x, y in zip(xs, ys))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.linear_algebra import vector_sum\n\ndef _negative_log_partial_j(x: Vector, y: float, beta: Vector, j: int) -> float:\n    \"\"\"\n    The jth partial derivative for one data point.\n    Here i is the index of the data point.\n    \"\"\"\n    return -(y - logistic(dot(x, beta))) * x[j]\n\ndef _negative_log_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n    \"\"\"\n    The gradient for one data point.\n    \"\"\"\n    return [_negative_log_partial_j(x, y, beta, j)\n            for j in range(len(beta))]\n\ndef negative_log_gradient(xs: List[Vector],\n                          ys: List[float],\n                          beta: Vector) -> Vector:\n    return vector_sum([_negative_log_gradient(x, y, beta)\n                       for x, y in zip(xs, ys)])",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Applying the Model"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.machine_learning import train_test_split\nimport random\nimport tqdm\n\nrandom.seed(0)\nx_train, x_test, y_train, y_test = train_test_split(rescaled_xs, ys, 0.33)\n\nlearning_rate = 0.01\n\n# pick a random starting point\nbeta = [random.random() for _ in range(3)]\n\nwith tqdm.trange(5000) as t:\n    for epoch in t:\n        gradient = negative_log_gradient(x_train, y_train, beta)\n        beta = gradient_step(beta, gradient, -learning_rate)\n        loss = negative_log_likelihood(x_train, y_train, beta)\n        t.set_description(f\"loss: {loss:.3f} beta: {beta}\")",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from scratch.working_with_data import scale\n\nmeans, stdevs = scale(xs)\nbeta_unscaled = [(beta[0]\n                  - beta[1] * means[1] / stdevs[1]\n                  - beta[2] * means[2] / stdevs[2]),\n                 beta[1] / stdevs[1],\n                 beta[2] / stdevs[2]]\n# [8.9, 1.6, -0.000288]",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Goodness of Fit"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "true_positives = false_positives = true_negatives = false_negatives = 0\n\nfor x_i, y_i in zip(x_test, y_test):\n    prediction = logistic(dot(beta, x_i))\n\n    if y_i == 1 and prediction >= 0.5:  # TP: paid and we predict paid\n        true_positives += 1\n    elif y_i == 1:                      # FN: paid and we predict unpaid\n        false_negatives += 1\n    elif prediction >= 0.5:             # FP: unpaid and we predict paid\n        false_positives += 1\n    else:                               # TN: unpaid and we predict unpaid\n        true_negatives += 1\n\nprecision = true_positives / (true_positives + false_positives)\nrecall = true_positives / (true_positives + false_negatives)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "predictions = [logistic(dot(beta, x_i)) for x_i in x_test]\nplt.scatter(predictions, y_test, marker='+')\nplt.xlabel(\"predicted probability\")\nplt.ylabel(\"actual outcome\")\nplt.title(\"Logistic Regression Predicted vs. Actual\")\nplt.show()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Support Vector Machines"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "- https://www.csie.ntu.edu.tw/~cjlin/libsvm/"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}